{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7lo9z8znuYx"
      },
      "source": [
        "# PoroDet: Nanoporosity Detection using Google Colab\n",
        "This notebook demonstrates how to use the PoroDet Python package to train a U-Net model, detect nanopores in new images, and analyze the results using Google Drive.\n",
        "Note: A user may use the local storage to upload the data. But it will be preferable to use the google drive for mutiple time access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pppvorjHn5uh"
      },
      "source": [
        "**Step 1: Install PoroDet**\n",
        "Install the package directly from GitHub. This ensures we are using the latest version of the code.\n",
        "Install the Augmentations lastest version if possible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL7paGqEnAZO",
        "outputId": "9cbcb38f-1661-4467-a137-70508109fb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Deep7285/PoroDet.git\n",
            "  Cloning https://github.com/Deep7285/PoroDet.git to /tmp/pip-req-build-3regzd83\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Deep7285/PoroDet.git /tmp/pip-req-build-3regzd83\n",
            "  Resolved https://github.com/Deep7285/PoroDet.git to commit f35bb0dc6cfcc6672906639af27ae3bece6a45a0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (4.13.0.90)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: albumentations>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from porodet==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.1->porodet==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.1->porodet==0.1.0) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations>=1.3.1->porodet==0.1.0) (0.0.24)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.3.1->porodet==0.1.0) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations>=1.3.1->porodet==0.1.0) (6.5.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->porodet==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->porodet==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->porodet==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->porodet==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.1->porodet==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.1->porodet==0.1.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.1->porodet==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->porodet==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->porodet==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->porodet==0.1.0) (3.0.3)\n",
            "Building wheels for collected packages: porodet\n",
            "  Building wheel for porodet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for porodet: filename=porodet-0.1.0-py3-none-any.whl size=22476 sha256=33461bb1343b64908ef58b5a52ab1978d564f12d7abfa0eca07eee17e36c061c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzz1fsrv/wheels/0b/9f/2b/7b5165f50c852e599881d3c840f13497b37841a1103cfa77c7\n",
            "Successfully built porodet\n",
            "Installing collected packages: porodet\n",
            "Successfully installed porodet-0.1.0\n",
            "Collecting albumentations==1.3.1\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.1) (1.16.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.1) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.1) (6.0.3)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.1)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.3.1) (4.13.0.90)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.15.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (3.6.1)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2026.1.14)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.6.0)\n",
            "Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "Successfully installed albumentations-1.3.1 qudida-0.0.4\n"
          ]
        }
      ],
      "source": [
        "# Install the PoroDet package directly from GitHub\n",
        "!pip install git+https://github.com/Deep7285/PoroDet.git\n",
        "\n",
        "# Install other dependencies if they aren't caught automatically\n",
        "!pip install albumentations==1.3.1  # Ensuring compatible version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXNuXGm-oGsK"
      },
      "source": [
        "**Step 2: Mount Google Drive or upload the input data**\n",
        "We need access to your dataset and a place to save the trained model.\n",
        "Note: keep both raw '.tif' file and its corrresponding binary mask. A sample will can be found in readme.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsjUc1KNoMLR",
        "outputId": "f005bdc9-67d6-44b3-8c0b-b13401b2aa35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Training Data: /content/drive/MyDrive/Rajat_Zr_nanoporosity/Masked_Dataset/Augmented_data\n",
            "Inference Data: /content/drive/MyDrive/Rajat_Zr_nanoporosity/Masked_Dataset/New_Inference_Images\n",
            "Output Folder: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab\n"
          ]
        }
      ],
      "source": [
        "# If data availaable on google drive then choose this\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Define your paths here\n",
        "TRAIN_DATA_DIR = \"/content/drive/MyDrive/Rajat_Zr_nanoporosity/Masked_Dataset/Augmented_data\"\n",
        "INFERENCE_DATA_DIR = \"/content/drive/MyDrive/Rajat_Zr_nanoporosity/Masked_Dataset/New_Inference_Images\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab\"\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Training Data: {TRAIN_DATA_DIR}\")\n",
        "print(f\"Inference Data: {INFERENCE_DATA_DIR}\")\n",
        "print(f\"Output Folder: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-falCT3Ys6O"
      },
      "outputs": [],
      "source": [
        "# if data available on local machine or folder then use this to upload\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload the file\n",
        "print(\"Please upload your dataset as a ZIP file (e.g., data.zip)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded zip\n",
        "zip_filename = next(iter(uploaded))\n",
        "print(f\"Uploaded: {zip_filename}\")\n",
        "\n",
        "# Extract the Zip file\n",
        "extract_path = \"/content/dataset\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "print(\"Extracting files\")\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extraction complete. Data is in: {extract_path}\")\n",
        "\n",
        "#  Update paths for dataset uploadeing\n",
        "# (Name the zip files contains folders named 'Augmented_data' and 'New_Inference_Images')\n",
        "# You might need to adjust these based on how users zip their folders\n",
        "TRAIN_DATA_DIR = os.path.join(extract_path, \"Augmented_data\")\n",
        "INFERENCE_DATA_DIR = os.path.join(extract_path, \"New_Inference_Images\")\n",
        "OUTPUT_DIR = \"/content/porodet_output\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\n--- PATHS UPDATED ---\")\n",
        "print(f\"Training Data: {TRAIN_DATA_DIR}\")\n",
        "print(f\"Inference Data: {INFERENCE_DATA_DIR}\")\n",
        "print(f\"Output Folder: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO7KlIOoesz"
      },
      "source": [
        "**Step 3: Train the Model**\n",
        "The porodet.train function expects a list of specific image files for training and validation. Since we are in a notebook (and can't use pop-up windows), we will write a small script to:\n",
        "1. Scan the data folder.\n",
        "2. Group original images with their augmented versions.\n",
        "3. Split them into Training and Validation sets.\n",
        "4. Run the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa4lRTayollB",
        "outputId": "937912fa-7263-405f-8df8-918d9d1e016a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU: Tesla T4 (15.83 GB VRAM)\n",
            "‚ö†Ô∏è Detected Standard GPU. Reducing image size to 512x512 to prevent crash.\n",
            "\n",
            "Grouping files...\n",
            "Found 26 unique original images.\n",
            "\n",
            "--- Starting PoroDet Training (512x512) ---\n",
            "\n",
            "Fold 1: Using device cuda\n",
            "Fold 1: 20 originals for training, 6 for validation\n",
            "Fold 1: Validation originals: ['Image_1', 'Image_17', 'Image_18', 'Image_2', 'Image_26', 'Image_8']\n",
            "Training set contains 320 images\n",
            "Validation set contains 96 images\n",
            "\n",
            "Starting training with verbose metrics to monitor progress\n",
            "Early stopping patience: 3\n",
            "Learning rate: 5e-05\n",
            "Weight decay: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 1/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [07:02<00:00,  2.64s/it, loss=0.3419]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 1: Train Loss 0.4614, Train Acc 0.9310 | Val Loss 0.3733, Val Acc 0.9762 | Val Prec 0.5203, Rec 0.2211, F1 0.3103, IoU 0.1837PR-AUC 0.24046968272141384, ROC-AUC 0.8434281466263029\n",
            "Fold 1: Saved new best model (val loss 0.3733)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 2/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [02:54<00:00,  1.09s/it, loss=0.2818]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 2: Train Loss 0.3260, Train Acc 0.9776 | Val Loss 0.2927, Val Acc 0.9786 | Val Prec 0.8602, Rec 0.1357, F1 0.2344, IoU 0.1327PR-AUC 0.3364830362434005, ROC-AUC 0.8411680153634721\n",
            "Fold 1: Saved new best model (val loss 0.2927)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 3/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [02:59<00:00,  1.12s/it, loss=0.2565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 3: Train Loss 0.2803, Train Acc 0.9788 | Val Loss 0.2610, Val Acc 0.9792 | Val Prec 0.7001, Rec 0.2421, F1 0.3598, IoU 0.2194PR-AUC 0.4050812778497371, ROC-AUC 0.8713683131021942\n",
            "Fold 1: Saved new best model (val loss 0.2610)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 4/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.13s/it, loss=0.2481]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 4: Train Loss 0.2478, Train Acc 0.9794 | Val Loss 0.2218, Val Acc 0.9797 | Val Prec 0.7553, Rec 0.2357, F1 0.3593, IoU 0.2190PR-AUC 0.4299260643408528, ROC-AUC 0.8819099790747545\n",
            "Fold 1: Saved new best model (val loss 0.2218)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 5/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.14s/it, loss=0.1865]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 5: Train Loss 0.2187, Train Acc 0.9801 | Val Loss 0.2173, Val Acc 0.9798 | Val Prec 0.6822, Rec 0.3091, F1 0.4255, IoU 0.2702PR-AUC 0.43565028846939885, ROC-AUC 0.9046230478931556\n",
            "Fold 1: Saved new best model (val loss 0.2173)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 6/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.13s/it, loss=0.1916]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 6: Train Loss 0.1958, Train Acc 0.9804 | Val Loss 0.1772, Val Acc 0.9804 | Val Prec 0.7432, Rec 0.2899, F1 0.4171, IoU 0.2635PR-AUC 0.4960901682476125, ROC-AUC 0.9078656084093896\n",
            "Fold 1: Saved new best model (val loss 0.1772)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 7/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.1597]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 7: Train Loss 0.1773, Train Acc 0.9807 | Val Loss 0.1638, Val Acc 0.9801 | Val Prec 0.6840, Rec 0.3306, F1 0.4457, IoU 0.2868PR-AUC 0.47088913344292016, ROC-AUC 0.922576722581201\n",
            "Fold 1: Saved new best model (val loss 0.1638)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 8/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.14s/it, loss=0.1646]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 8: Train Loss 0.1592, Train Acc 0.9812 | Val Loss 0.1470, Val Acc 0.9805 | Val Prec 0.6796, Rec 0.3651, F1 0.4750, IoU 0.3115PR-AUC 0.5128283776112669, ROC-AUC 0.9149949616353348\n",
            "Fold 1: Saved new best model (val loss 0.1470)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 9/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:03<00:00,  1.15s/it, loss=0.1568]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 9: Train Loss 0.1430, Train Acc 0.9815 | Val Loss 0.1386, Val Acc 0.9811 | Val Prec 0.7426, Rec 0.3355, F1 0.4622, IoU 0.3005PR-AUC 0.5371820136642915, ROC-AUC 0.9289414412829085\n",
            "Fold 1: Saved new best model (val loss 0.1386)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 10/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:03<00:00,  1.15s/it, loss=0.1197]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 10: Train Loss 0.1303, Train Acc 0.9816 | Val Loss 0.1219, Val Acc 0.9808 | Val Prec 0.6775, Rec 0.3961, F1 0.4999, IoU 0.3332PR-AUC 0.5449273166644248, ROC-AUC 0.9296067822808126\n",
            "Fold 1: Saved new best model (val loss 0.1219)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 11/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.14s/it, loss=0.1180]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 11: Train Loss 0.1192, Train Acc 0.9820 | Val Loss 0.1133, Val Acc 0.9817 | Val Prec 0.7787, Rec 0.3386, F1 0.4720, IoU 0.3089PR-AUC 0.5750456909512363, ROC-AUC 0.9410361009904427\n",
            "Fold 1: Saved new best model (val loss 0.1133)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 12/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0845]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 12: Train Loss 0.1101, Train Acc 0.9822 | Val Loss 0.1060, Val Acc 0.9814 | Val Prec 0.6658, Rec 0.4606, F1 0.5445, IoU 0.3741PR-AUC 0.577986934631646, ROC-AUC 0.9456621719771471\n",
            "Fold 1: Saved new best model (val loss 0.1060)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 13/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0802]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 13: Train Loss 0.1017, Train Acc 0.9825 | Val Loss 0.0975, Val Acc 0.9821 | Val Prec 0.7322, Rec 0.4075, F1 0.5236, IoU 0.3546PR-AUC 0.5864770468809279, ROC-AUC 0.9495029991347091\n",
            "Fold 1: Saved new best model (val loss 0.0975)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 14/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.13s/it, loss=0.0928]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 14: Train Loss 0.0948, Train Acc 0.9826 | Val Loss 0.0937, Val Acc 0.9819 | Val Prec 0.6930, Rec 0.4495, F1 0.5453, IoU 0.3748PR-AUC 0.5968694218340163, ROC-AUC 0.9479429422590967\n",
            "Fold 1: Saved new best model (val loss 0.0937)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 15/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:04<00:00,  1.15s/it, loss=0.0681]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 15: Train Loss 0.0892, Train Acc 0.9826 | Val Loss 0.0895, Val Acc 0.9814 | Val Prec 0.6685, Rec 0.4608, F1 0.5455, IoU 0.3751PR-AUC 0.5809713257662353, ROC-AUC 0.950664982890697\n",
            "Fold 1: Saved new best model (val loss 0.0895)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 16/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0840]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 16: Train Loss 0.0839, Train Acc 0.9829 | Val Loss 0.0808, Val Acc 0.9823 | Val Prec 0.7119, Rec 0.4474, F1 0.5495, IoU 0.3788PR-AUC 0.6060846323661876, ROC-AUC 0.955813644442486\n",
            "Fold 1: Saved new best model (val loss 0.0808)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 17/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:01<00:00,  1.14s/it, loss=0.0652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 17: Train Loss 0.0792, Train Acc 0.9829 | Val Loss 0.0774, Val Acc 0.9828 | Val Prec 0.7221, Rec 0.4690, F1 0.5687, IoU 0.3973PR-AUC 0.6339564714120337, ROC-AUC 0.9605731032018812\n",
            "Fold 1: Saved new best model (val loss 0.0774)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 18/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:03<00:00,  1.14s/it, loss=0.0580]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 18: Train Loss 0.0753, Train Acc 0.9832 | Val Loss 0.0723, Val Acc 0.9829 | Val Prec 0.7385, Rec 0.4551, F1 0.5631, IoU 0.3919PR-AUC 0.6326794163942605, ROC-AUC 0.9598342918454862\n",
            "Fold 1: Saved new best model (val loss 0.0723)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 19/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0745]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 19: Train Loss 0.0719, Train Acc 0.9832 | Val Loss 0.0706, Val Acc 0.9831 | Val Prec 0.7403, Rec 0.4645, F1 0.5708, IoU 0.3994PR-AUC 0.6437010280274972, ROC-AUC 0.9630150080652944\n",
            "Fold 1: Saved new best model (val loss 0.0706)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 20/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0564]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 20: Train Loss 0.0683, Train Acc 0.9835 | Val Loss 0.0706, Val Acc 0.9827 | Val Prec 0.7053, Rec 0.4862, F1 0.5756, IoU 0.4041PR-AUC 0.6297111390696598, ROC-AUC 0.9605430830095223\n",
            "Fold 1: Validation loss did not improve. Counter: 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 21/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [02:54<00:00,  1.09s/it, loss=0.0546]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 21: Train Loss 0.0655, Train Acc 0.9835 | Val Loss 0.0669, Val Acc 0.9830 | Val Prec 0.7334, Rec 0.4649, F1 0.5691, IoU 0.3977PR-AUC 0.6356739069310938, ROC-AUC 0.9592229689664649\n",
            "Fold 1: Saved new best model (val loss 0.0669)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 22/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0541]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 22: Train Loss 0.0629, Train Acc 0.9836 | Val Loss 0.0632, Val Acc 0.9831 | Val Prec 0.7073, Rec 0.5114, F1 0.5936, IoU 0.4220PR-AUC 0.6405803519133462, ROC-AUC 0.9648428467509632\n",
            "Fold 1: Saved new best model (val loss 0.0632)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 23/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:02<00:00,  1.14s/it, loss=0.0413]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 23: Train Loss 0.0603, Train Acc 0.9839 | Val Loss 0.0640, Val Acc 0.9822 | Val Prec 0.6728, Rec 0.5164, F1 0.5843, IoU 0.4128PR-AUC 0.6147420904433771, ROC-AUC 0.9642315564932835\n",
            "Fold 1: Validation loss did not improve. Counter: 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 24/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [02:54<00:00,  1.09s/it, loss=0.0680]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 24: Train Loss 0.0583, Train Acc 0.9841 | Val Loss 0.0620, Val Acc 0.9824 | Val Prec 0.6544, Rec 0.5771, F1 0.6133, IoU 0.4423PR-AUC 0.6572395446143184, ROC-AUC 0.9631158348288398\n",
            "Fold 1: Saved new best model (val loss 0.0620)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 | Epoch 25/25 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [03:03<00:00,  1.15s/it, loss=0.0520]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 & Epoch 25: Train Loss 0.0558, Train Acc 0.9843 | Val Loss 0.0586, Val Acc 0.9837 | Val Prec 0.7398, Rec 0.5033, F1 0.5991, IoU 0.4276PR-AUC 0.665311058874434, ROC-AUC 0.9673061395461103\n",
            "Fold 1: Saved new best model (val loss 0.0586)\n",
            "Fold 1: Training finished. Final model saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Training_Session/fold_1_final_model.pth\n",
            "Fold 1: Saved metrics CSV to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Training_Session/fold_1_metrics.csv\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "import porodet\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from porodet.training import get_original_and_augmented_groups\n",
        "\n",
        "# Check what hardware we are running on, code will check the hardware and process the data accordingly.\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"Found GPU: {gpu_name} ({total_mem:.2f} GB VRAM)\")\n",
        "\n",
        "    if total_mem < 20:\n",
        "        # For T4 (Free Colab) -> 15GB VRAM\n",
        "        print(\"‚ö†Ô∏è Detected Standard GPU. Reducing image size to 512x512 to prevent crash.\")\n",
        "        TARGET_SIZE = (512, 512)\n",
        "        BATCH_SIZE = 2 # 512x512 is small enough to run batch=2 safely\n",
        "    else:\n",
        "        # For A100 (Pro Colab) -> 40GB+ VRAM\n",
        "        print(\"üöÄ Detected High-End GPU. Using full 1024x1024 resolution.\")\n",
        "        TARGET_SIZE = (1024, 1024)\n",
        "        BATCH_SIZE = 2 # change the batch size as per hardware compatibilty\n",
        "else:\n",
        "    print(\"‚ùå No GPU found! Training will be extremely slow.\")\n",
        "    TARGET_SIZE = (256, 256) # Emergency mode for CPU\n",
        "    BATCH_SIZE = 1\n",
        "\n",
        "# Group images\n",
        "print(\"\\nGrouping files...\")\n",
        "original_groups = get_original_and_augmented_groups(TRAIN_DATA_DIR)\n",
        "original_images = list(original_groups.keys())\n",
        "print(f\"Found {len(original_images)} unique original images.\")\n",
        "\n",
        "# Create Train/Val split\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "train_indices, val_indices = next(kf.split(original_images))\n",
        "\n",
        "train_originals = [original_images[i] for i in train_indices]\n",
        "val_originals = [original_images[i] for i in val_indices]\n",
        "\n",
        "# Define Training Output Folder where training logs and trained model will be saved\n",
        "training_output = os.path.join(OUTPUT_DIR, \"Training_Session\")\n",
        "os.makedirs(training_output, exist_ok=True)\n",
        "\n",
        "# 4. Start Training\n",
        "print(f\"\\n--- Starting model training ({TARGET_SIZE[0]}x{TARGET_SIZE[1]}) ---\")\n",
        "\n",
        "# We pass 'resize_to' to override the default 1024 size\n",
        "model, history = porodet.train(\n",
        "    data_dir=TRAIN_DATA_DIR,\n",
        "    output_dir=training_output,\n",
        "    train_originals=train_originals,\n",
        "    val_originals=val_originals,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    resize_to=TARGET_SIZE,\n",
        "    epochs=25,  # optimize the epoch value to get the loss plateau\n",
        "    learning_rate=5e-5, # adjust the learning rate to optimization\n",
        "    patience=3,\n",
        "    fold_id=1  #adjust the fold id. Idealy keep 3.\n",
        ")\n",
        "\n",
        "print(\"Training Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UGs88I0_EKQ"
      },
      "source": [
        "**Step 4: Detect Pores (Inference)**\n",
        "Now we take the best model saved from the previous step and apply it to new, unseen images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aP1qlHD_Jvm",
        "outputId": "1d6265e6-8b51-4eeb-e0cf-5fe503f8b428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Model: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Training_Session/fold_1_best_model.pth\n",
            "Found 1 images for inference.\n",
            "Processing: Image_19.tif...\n",
            "\n",
            "Inference done. Results saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Inference_Results\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "# Find the best model file from the training output\n",
        "model_files = glob(os.path.join(training_output, \"*_best_model.pth\"))\n",
        "if not model_files:\n",
        "    raise FileNotFoundError(\"No trained model found!\")\n",
        "best_model_path = model_files[0]\n",
        "print(f\"Loading the Model: {best_model_path}\")\n",
        "\n",
        "# Load the Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = porodet.UNet(in_channels=1, out_channels=1).to(device)\n",
        "\n",
        "# Added weights_only=False to fix PyTorch 2.6 compatibility\n",
        "checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Run Inference on New Images\n",
        "inference_images = sorted(glob(os.path.join(INFERENCE_DATA_DIR, \"*.tif\"))) # Adjust extension if needed (.jpg/.png)\n",
        "\n",
        "if not inference_images:\n",
        "    print(\"No images found in inference folder.\")\n",
        "else:\n",
        "    print(f\"Found {len(inference_images)} images for inference.\")\n",
        "\n",
        "    inference_output_dir = os.path.join(OUTPUT_DIR, \"Inference_Results\")\n",
        "    os.makedirs(inference_output_dir, exist_ok=True)\n",
        "\n",
        "    for img_path in inference_images:\n",
        "        img_name = os.path.basename(img_path)\n",
        "        print(f\"Processing: {img_name}...\")\n",
        "\n",
        "        # Detection\n",
        "        original, prob_map, binary_mask = porodet.detect(model, img_path, device, threshold=0.5)\n",
        "\n",
        "        # Save the mask for the next step i.e Analysis\n",
        "        mask_filename = os.path.splitext(img_name)[0] + \"_mask.png\"\n",
        "        mask_save_path = os.path.join(inference_output_dir, mask_filename)\n",
        "        cv2.imwrite(mask_save_path, (binary_mask * 255).astype(np.uint8))\n",
        "\n",
        "        # Optional: Save visualization overlay\n",
        "        # package's visualization tools or simple matplotlib can be used)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1); plt.imshow(original, cmap='gray'); plt.title(\"Original\")\n",
        "        plt.subplot(1, 2, 2); plt.imshow(prob_map, cmap='hot'); plt.title(\"Prediction\")\n",
        "        plt.savefig(os.path.join(inference_output_dir, f\"{img_name}_vis.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"\\nInference done. Results saved to: {inference_output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD0-KNPu_Nk6"
      },
      "source": [
        "**Step 5: Analyze Results**\n",
        "Finally, we calculate porosity statistics (area, pore count, shape) using the masks generated in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8dNw0mt_RU_",
        "outputId": "5a628f5d-6ecb-4b96-b787-b6498d0582c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing 1 masks...\n",
            "Analyzing: Image_19_mask.png\n",
            "Image_19.tif: Nanoporosity = 0.65%\n",
            "Total number of nanopores detected: 211\n",
            "Number of mostly circular nanopores (aspect ratio ‚â§ 2.0): 176\n",
            "Number of elongated nanopores (aspect ratio > 2.0): 35\n",
            "Average size: 32.42 pixels\n",
            "Average aspect ratio: 1.57\n",
            "Average diameter: 5.88 pixels\n",
            "Size histogram saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report/Image_19_size_histogram.png\n",
            "Aspect ratio histogram saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report/Image_19_aspect_ratio_histogram.png\n",
            "Diameter histogram saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report/Image_19_diameter_histogram.png\n",
            "Circular overlay saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report/Image_19_circular_overlay.png\n",
            "Elongated overlay saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report/Image_19_elongated_overlay.png\n",
            "\n",
            "Analysis Report saved to: /content/drive/MyDrive/Rajat_Zr_nanoporosity/package_testing_colab/Analysis_Report\n"
          ]
        }
      ],
      "source": [
        "# Get the list of generated masks\n",
        "mask_files = sorted(glob(os.path.join(inference_output_dir, \"*_mask.png\")))\n",
        "\n",
        "if not mask_files:\n",
        "    print(\"No masks found to analyze.\")\n",
        "else:\n",
        "    analysis_output_dir = os.path.join(OUTPUT_DIR, \"Analysis_Report\")\n",
        "    os.makedirs(analysis_output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Analyzing {len(mask_files)} masks...\")\n",
        "\n",
        "    for mask_path in mask_files:\n",
        "        print(f\"Analyzing: {os.path.basename(mask_path)}\")\n",
        "\n",
        "        # Analysis\n",
        "        # porodet.analyze takes the mask path and output directory\n",
        "        porodet.analyze(\n",
        "            mask_path=mask_path,\n",
        "            output_dir=analysis_output_dir,\n",
        "            aspect_ratio_threshold=2.0 # Threshold to distinguish pores vs cracks, adjust it accordingly\n",
        "        )\n",
        "\n",
        "    print(f\"\\nAnalysis Report saved to: {analysis_output_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
