{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a4da5b",
   "metadata": {},
   "source": [
    "# Porodet workflow for running on local machine\n",
    "This notebook guides you through the complete workflow of the PoroDet package on your local machine. It uses pop-up windows (GUI) to make selecting files and folders easy. Run this script **prefrebly run on VS Code (Visual studio code)**. Download and install the VS Code here: https://code.visualstudio.com/download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e6ea0",
   "metadata": {},
   "source": [
    "**Step 1: Install the porodet repository**  \n",
    "Install the porodet repository in the terminal if you are using   \n",
    "**Windows:**  \n",
    "Run the following coomand in the terminal (a VS code provide the terminal)  \n",
    "C:\\users\\home> pip install git+https://github.com/Deep7285/Porodet.git  \n",
    " \n",
    "**Linux:**  \n",
    "1. Create the conda enviroment. read how to create the conda environment here: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\n",
    "2. Run the following coomand in the terminal in created environment (a VS code provide the terminal).  \n",
    "(base) user1@my_pc:~$ conda activate my_new_env  \n",
    "(my_new_env) user1@my_pc:~& pip install git+https://github.com/Deep7285/Porodet.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a492a",
   "metadata": {},
   "source": [
    "**Step 2: Import & Setup**  \n",
    "Run the following code cell to load the package and set and dependencyies.  \n",
    "\n",
    "**Note: User can directly jump to detection step if you alrady trained the model. after running this cell code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece41fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoroDet Package Loaded (Version: 0.1.0)\n",
      "Ready for the next command...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import porodet\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "# Helper to hide the root tkinter window\n",
    "def get_gui_root():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw() \n",
    "    root.attributes('-topmost', True) # Bring the dialog to the front\n",
    "    return root\n",
    "\n",
    "print(f\"PoroDet Package Loaded (Version: {porodet.__version__})\")\n",
    "print(\"Ready for the next command...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3036f",
   "metadata": {},
   "source": [
    "**Step 3: Augmentation files checkpoint**  \n",
    "The following Cell code helps users to check whether the augmented data already exist or not. It will help users to avoid generating mulpltile augmented datasets by selecting the  augmented folder where code will check if folder has augmented data or not.  \n",
    "1. If augmented data is availble then it asks you to locate it and then can proceed for model training.  \n",
    "2. If not then it tells you to run the next Augmentating the data step 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select your existing Augmented Data folder\n",
      "Data Exists in: C:/Users/deepa/Downloads/augmented_images_20260214_144918\n",
      "Skipping Augmentation Step. Users can proceed to the model training step.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variable to track if augmentation is needed\n",
    "augment_needed = True\n",
    "augmented_data_dir = None\n",
    "\n",
    "# Ask user if they already have augmented data\n",
    "root = get_gui_root()\n",
    "has_data = messagebox.askyesno(\"Data Check\", \"Do you already have an Augmented data in folder?\")\n",
    "root.destroy()\n",
    "\n",
    "if has_data:\n",
    "    print(\"Please select your existing Augmented Data folder\")\n",
    "    root = get_gui_root()\n",
    "    augmented_data_dir = filedialog.askdirectory(title=\"Select Augmented Data Folder\")\n",
    "    root.destroy()\n",
    "    \n",
    "    if augmented_data_dir:\n",
    "        print(f\"Data Exists in: {augmented_data_dir}\")\n",
    "        print(\"Skipping Augmentation Step. Users can proceed to the model training step.\")\n",
    "        augment_needed = False\n",
    "    else:\n",
    "        print(\"No folder selected. You might need to run Augmentation.\")\n",
    "else:\n",
    "    print(\"No augmented data found.\")\n",
    "    print(\"Please run the Step 4: Data Augmentation cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58af68",
   "metadata": {},
   "source": [
    "**Step 4: Data Augmentation (Run if needed)**  \n",
    "This cell ask you to selec the raw file folder where user have saved the raw TEM images and it binary mask.  \n",
    "**It is recommonded that user shoud name the raw file name properly, it will help in generating the augmented dataset. A sample datasets can be accessed in \"PoroDet/Sample_Dataset/\" in package repo.**  \n",
    "1. Select your Raw Images folder (containing .tif images and _mask.png masks).  \n",
    "2. It will create a new folder with augmented versions of raw datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b18ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data Augmentation\n",
      "Please select your RAW images files folder.\n",
      "TEM Image Augmentation\n",
      "Waiting for folder selection dialog to appear\n",
      "If no dialog appears, check your taskbar or behind other windows.\n",
      "Dialog will timeout in 15 seconds if not used.\n",
      "You Selected directory: C:/Users/deepa/Downloads/100_Res\n",
      "10 augmentations per image will be created\n",
      "Found 26 raw images\n",
      "Generating 10 augmentations for each image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 26/26 [01:15<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. Files saved to: C:/Users/deepa/Downloads\\augmented_images_20260214_144918\n",
      "\n",
      " Augmentation Complete.\n",
      "Check the output folder created. It usually ends in 'augmented_images_...').\n",
      "Please run Step 3 again to select this new folder as your dataset to confirm it worked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if augment_needed:\n",
    "    print(\"Initializing Data Augmentation\")\n",
    "    print(\"Please select your RAW images files folder.\")\n",
    "    \n",
    "    # Import the main GUI function directly from the module\n",
    "    from porodet.augmentation import main as run_augmentation_gui\n",
    "    \n",
    "    # Run the tool\n",
    "    run_augmentation_gui()\n",
    "    \n",
    "    print(\"\\n Augmentation Complete.\")\n",
    "    print(\"Check the output folder created. It usually ends in 'augmented_images_...').\")\n",
    "    print(\"Please run Step 3 again to select this new folder as your dataset to confirm it worked\")\n",
    "else:\n",
    "    print(\"Skipping Data Augmentation (Data already provided).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba899b4",
   "metadata": {},
   "source": [
    "**Step 5: Model Training**  \n",
    "1. The following code cell trains the Unet model from scratch.  \n",
    "2. The code cell allow users to adjust the hyperparameter for model training and fine-tuning. Check your system configuration to select the hyperparameter to avoid the kernel crash.  \n",
    "2. After adjusting the hyperparameters run the cell and this will Pop-up a window asking to select the folder of training dataset (select the augmented_image_ folder).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiallizing Training...\n",
      "Select the training set folder...\n",
      "\n",
      " Starting training with custom parameters:\n",
      "   - Batch Size: 1\n",
      "   - Epochs: 10\n",
      "   - Folds: 2\n",
      "   - Image Size: (512, 512)\n",
      "   - Output: C:/Users/deepa/Downloads/augmented_images_20260214_144918\\nanopore_model_20260214_151437_custom\n",
      "\n",
      "Starting Fold 1/2\n",
      "\n",
      "Fold 1: Using device cpu\n",
      "Fold 1: 13 originals for training, 13 for validation\n",
      "Fold 1: Validation originals: ['Image_1', 'Image_10', 'Image_11', 'Image_14', 'Image_17', 'Image_18', 'Image_2', 'Image_20', 'Image_23', 'Image_25', 'Image_26', 'Image_7', 'Image_8']\n",
      "Training set contains 143 images\n",
      "Validation set contains 143 images\n",
      "\n",
      "Starting training with verbose metrics to monitor progress\n",
      "Early stopping patience: 5\n",
      "Learning rate: 1e-05\n",
      "Weight decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 1/10 [train]: 100%|██████████| 143/143 [11:07<00:00,  4.67s/it, loss=0.6205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 & Epoch 1: Train Loss 0.6981, Train Acc 0.5598 | Val Loss 0.6564, Val Acc 0.8864 | Val Prec 0.1342, Rec 0.6229, F1 0.2208, IoU 0.1241PR-AUC 0.14935351264237393, ROC-AUC 0.8257952284324483\n",
      "Fold 1: Saved new best model (val loss 0.6564)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 2/10 [train]: 100%|██████████| 143/143 [13:08<00:00,  5.52s/it, loss=0.5256] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 & Epoch 2: Train Loss 0.5556, Train Acc 0.9308 | Val Loss 0.4960, Val Acc 0.9592 | Val Prec 0.3002, Rec 0.4353, F1 0.3553, IoU 0.2161PR-AUC 0.25911860922376156, ROC-AUC 0.8769097544762908\n",
      "Fold 1: Saved new best model (val loss 0.4960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 3/10 [train]: 100%|██████████| 143/143 [09:03<00:00,  3.80s/it, loss=0.4533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 & Epoch 3: Train Loss 0.4788, Train Acc 0.9712 | Val Loss 0.4213, Val Acc 0.9720 | Val Prec 0.4255, Rec 0.2411, F1 0.3078, IoU 0.1819PR-AUC 0.25083973091231615, ROC-AUC 0.8638905298627639\n",
      "Fold 1: Saved new best model (val loss 0.4213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 4/10 [train]: 100%|██████████| 143/143 [09:20<00:00,  3.92s/it, loss=0.4506]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import the internal tools directly\n",
    "from porodet.training import train_nanopore_detector, get_original_and_augmented_groups\n",
    "\n",
    "# Adjust the hyperparameters here as needed\n",
    "BATCH_SIZE = 1        # Increased batch size (keep lower if you get memory errors or kernel crash)\n",
    "EPOCHS = 10           # Increase epochs for better training \n",
    "LEARNING_RATE = 1e-5  # Adjust learning rate \n",
    "FOLDS = 2            # K-Fold Cross Validation (standard is 3)\n",
    "PATIENCE = 5          # Early stopping patience if loss does not improve\n",
    "RESIZE_TO = (512, 512) # Lower resolution to save memory (Default is 1024, 1024). \n",
    "                       # if system allows, you can increase this back to 1024 for better results but it will require more GPU memory.\n",
    "\n",
    "# Select the data directory (with augmented data)\n",
    "print(\"Initiallizing Training...\")\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes('-topmost', True)\n",
    "print(\"Select the training set folder...\")\n",
    "data_dir = filedialog.askdirectory(title=\"Select Training Directory\")\n",
    "root.destroy()\n",
    "\n",
    "if not data_dir:\n",
    "    print(\"No directory selected. Training cancelled.\")\n",
    "else:\n",
    "    # Ouput directory with timestamp to avoid overwriting\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    base_output_dir = os.path.join(data_dir, f'nanopore_model_{timestamp}_custom')\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n Starting training with custom parameters:\")\n",
    "    print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"   - Epochs: {EPOCHS}\")\n",
    "    print(f\"   - Folds: {FOLDS}\")\n",
    "    print(f\"   - Image Size: {RESIZE_TO}\")\n",
    "    print(f\"   - Output: {base_output_dir}\")\n",
    "\n",
    "    # --- 4. PREPARE DATA GROUPS ---\n",
    "    original_groups = get_original_and_augmented_groups(data_dir)\n",
    "    original_images = list(original_groups.keys())\n",
    "    \n",
    "    if len(original_images) < FOLDS:\n",
    "        print(f\"Error: Not enough original images ({len(original_images)}) for {FOLDS} folds.\")\n",
    "    else:\n",
    "        # Run the K-Fold Cross Validation\n",
    "        kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42) \n",
    "        fold_histories = []\n",
    "\n",
    "        for fold_id, (train_idx, val_idx) in enumerate(kf.split(original_images), start=1):\n",
    "            train_originals = [original_images[i] for i in train_idx]\n",
    "            val_originals = [original_images[i] for i in val_idx]\n",
    "\n",
    "            fold_output_dir = os.path.join(base_output_dir, f'fold_{fold_id}')\n",
    "            os.makedirs(fold_output_dir, exist_ok=True)\n",
    "\n",
    "            print(f\"\\nStarting Fold {fold_id}/{FOLDS}\")\n",
    "            \n",
    "            # Call the internal function with defined  hyperparameters\n",
    "            model, history = train_nanopore_detector(data_dir=data_dir, output_dir=fold_output_dir, train_originals=train_originals, val_originals=val_originals,batch_size=BATCH_SIZE,      \n",
    "                             epochs=EPOCHS, learning_rate=LEARNING_RATE, patience=PATIENCE,         \n",
    "                             weight_decay=1e-4,          # Keep default or change\n",
    "                             prob_threshold=0.5,         # Adjust if you want to be more or less strict in detection \n",
    "                             resize_to=RESIZE_TO, fold_id=fold_id )\n",
    "            \n",
    "            best_loss = min(history[\"val_loss\"]) if len(history[\"val_loss\"]) > 0 else None\n",
    "            fold_histories.append({ \"fold\": fold_id, \"best_val_loss\": best_loss})\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # Saving the trained models and training history for each fold\n",
    "        summary_csv = os.path.join(base_output_dir, \"Model_training_summary.csv\")\n",
    "        with open(summary_csv, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"fold\", \"best_val_loss\"])\n",
    "            for fh in fold_histories:\n",
    "                writer.writerow([fh[\"fold\"], fh[\"best_val_loss\"]])\n",
    "        \n",
    "        print(f\"\\n Model Training Complete. Training Summary saved to: {summary_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea3d9d",
   "metadata": {},
   "source": [
    "**Step 6: Nanoporosity Detection (Inference on New Images)**  \n",
    "This step uses the trained model to detect the nanoporosities in new images, generate the binary mask, probability heatmap.   \n",
    "**A user don't need to train the model every time, a trained model can directly use for detection**  \n",
    "1. Run the step 2 and directly jump to detection step if you have alrady trained model.  \n",
    "2. Run the cell and a window will pop-up asking to select trained Model (.pth), Look in the training output folder.  \n",
    "3. After selecting the trained model a window will pop-up asking to select the new TEM image/s for detection.  \n",
    "3. Output will be saved in a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f3249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Detection...\n",
      "Select the trained model file (.pth).\n",
      "Select the new TEM image/s to for detection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Detection...\")\n",
    "print(\"Select the trained model file (.pth).\")\n",
    "print(\"Select the new TEM image/s to for detection.\")\n",
    "\n",
    "# Import the detector GUI entry point\n",
    "from porodet.detector import main as run_detector_gui\n",
    "\n",
    "# Run it\n",
    "run_detector_gui()\n",
    "\n",
    "print(\"\\nDetection Complete.\")\n",
    "print(\"Check the folder containing your image/s for the results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6e71d",
   "metadata": {},
   "source": [
    "**Step 7: Detailed Analysis**\n",
    "Calculate porosity, histograms, and classify pores vs. cracks.\n",
    "1. A pop-up window will ask to select the Mask image (_mask.png) generated in detection step.\n",
    "2. The output will be saved in CSVs and histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc782e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing the Nanoporosity Analysis...\")\n",
    "print(\"Select the MASK file (_mask.png) generated in the detection step.\")\n",
    "print(\"Select an output folder to save the report.\")\n",
    "\n",
    "# Import the analyser GUI entry point\n",
    "from porodet.analyser import main as run_analysis_gui\n",
    "\n",
    "# Run it\n",
    "run_analysis_gui()\n",
    "\n",
    "print(\"\\nAnalysis Complete. Check the folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
