{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec7e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model selected. Exiting.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PoroDet_finetune.py\n",
    "\n",
    "Fine-tune a pretrained PoroDet U-Net model on new TEM image–mask pairs.\n",
    "\n",
    "Expected data layout in the chosen folder:\n",
    "\n",
    "    Image_01.tif\n",
    "    Image_01_mask.png\n",
    "    Image_02.tif\n",
    "    Image_02_mask.png\n",
    "    ...\n",
    "\n",
    "Masks must be PNGs with the same base filename + \"_mask\".\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Basic configuration\n",
    "# ----------------------------\n",
    "\n",
    "image_size = 1024          # change to 2048 if you really want (watch GPU memory)\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-4\n",
    "patience = 3               # early stopping if val loss doesn't improve\n",
    "freeze_encoder = False     # True = only fine-tune decoder\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model (same U-Net as trainer)\n",
    "# ----------------------------\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.conv1 = DoubleConv(in_channels, 64, dropout_rate)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128, dropout_rate)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256, dropout_rate)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512, dropout_rate)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024, dropout_rate)\n",
    "\n",
    "        # decoder\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512, dropout_rate)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256, dropout_rate)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128, dropout_rate)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64, dropout_rate)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "\n",
    "        c5 = self.conv5(p4)\n",
    "\n",
    "        u6 = self.up6(c5)\n",
    "        m6 = torch.cat([u6, c4], dim=1)\n",
    "        c6 = self.conv6(m6)\n",
    "\n",
    "        u7 = self.up7(c6)\n",
    "        m7 = torch.cat([u7, c3], dim=1)\n",
    "        c7 = self.conv7(m7)\n",
    "\n",
    "        u8 = self.up8(c7)\n",
    "        m8 = torch.cat([u8, c2], dim=1)\n",
    "        c8 = self.conv8(m8)\n",
    "\n",
    "        u9 = self.up9(c8)\n",
    "        m9 = torch.cat([u9, c1], dim=1)\n",
    "        c9 = self.conv9(m9)\n",
    "\n",
    "        out = self.out_conv(c9)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset\n",
    "# ----------------------------\n",
    "\n",
    "class NanoporeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Simple dataset for image + mask pairs in a single folder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = data_dir\n",
    "        all_files = sorted(os.listdir(data_dir))\n",
    "\n",
    "        self.image_files = []\n",
    "        for fname in all_files:\n",
    "            if fname.lower().endswith(\".tif\"):\n",
    "                base = os.path.splitext(fname)[0]\n",
    "                mask_name = base + \"_mask.png\"\n",
    "                if mask_name in all_files:\n",
    "                    self.image_files.append(fname)\n",
    "\n",
    "        print(f\"Found {len(self.image_files)} image/mask pairs in {data_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        base = os.path.splitext(img_name)[0]\n",
    "        mask_name = base + \"_mask.png\"\n",
    "\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        mask_path = os.path.join(self.data_dir, mask_name)\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None or mask is None:\n",
    "            raise RuntimeError(f\"Could not read image or mask: {img_name}\")\n",
    "\n",
    "        # resize\n",
    "        image = cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (image_size, image_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # normalise\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "\n",
    "        # to (C, H, W)\n",
    "        image = torch.from_numpy(image).unsqueeze(0)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helper functions\n",
    "# ----------------------------\n",
    "\n",
    "def choose_file(title, pattern=\"*.pth\"):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    path = filedialog.askopenfilename(title=title, filetypes=[(\"Files\", pattern), (\"All files\", \"*.*\")])\n",
    "    root.destroy()\n",
    "    return path\n",
    "\n",
    "\n",
    "def choose_dir(title):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    path = filedialog.askdirectory(title=title)\n",
    "    root.destroy()\n",
    "    return path\n",
    "\n",
    "\n",
    "def load_pretrained_model(path, device):\n",
    "    print(f\"\\nLoading pretrained model from:\\n  {path}\")\n",
    "    model = UNet(in_channels=1, out_channels=1, dropout_rate=0.2).to(device)\n",
    "\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    # support both \"training checkpoint\" dict and raw state_dict\n",
    "    if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        print(f\"Loaded model_state_dict (epoch={checkpoint.get('epoch', 'unknown')})\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"Loaded state_dict directly (no metadata).\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def freeze_encoder_part(model: UNet):\n",
    "    \"\"\"\n",
    "    Freeze encoder and bottleneck so only the decoder is updated.\n",
    "    \"\"\"\n",
    "    print(\"Freezing encoder + bottleneck layers.\")\n",
    "    encoder_modules = [\n",
    "        model.conv1, model.pool1,\n",
    "        model.conv2, model.pool2,\n",
    "        model.conv3, model.pool3,\n",
    "        model.conv4, model.pool4,\n",
    "        model.conv5,\n",
    "    ]\n",
    "    for m in encoder_modules:\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics\n",
    "# ----------------------------\n",
    "\n",
    "def compute_pixel_metrics(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"\n",
    "    y_true, y_prob: 1D numpy arrays over all pixels in the validation set.\n",
    "    Returns dict with accuracy, precision, recall, F1, IoU, Dice, PR-AUC, ROC-AUC.\n",
    "    \"\"\"\n",
    "    y_pred = (y_prob >= threshold).astype(np.uint8)\n",
    "\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "    acc = (tp + tn) / total if total > 0 else 0.0\n",
    "\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "\n",
    "    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n",
    "    dice = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n",
    "\n",
    "    # AUC metrics are undefined if only one class present\n",
    "    if np.unique(y_true).size > 1:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_prob)\n",
    "        except ValueError:\n",
    "            roc_auc = float(\"nan\")\n",
    "        try:\n",
    "            pr_auc = average_precision_score(y_true, y_prob)\n",
    "        except ValueError:\n",
    "            pr_auc = float(\"nan\")\n",
    "    else:\n",
    "        roc_auc = float(\"nan\")\n",
    "        pr_auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"iou\": iou,\n",
    "        \"dice\": dice,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"roc_auc\": roc_auc,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Train / eval loops\n",
    "# ----------------------------\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, threshold=0.5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, masks in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # training accuracy (per pixel)\n",
    "        probs = torch.sigmoid(out).detach().cpu().numpy().ravel()\n",
    "        labels = masks.detach().cpu().numpy().ravel()\n",
    "        preds = (probs >= threshold).astype(np.uint8)\n",
    "\n",
    "        correct += np.sum(preds == labels)\n",
    "        total += labels.size\n",
    "\n",
    "    avg_loss = running_loss / max(1, len(loader))\n",
    "    train_acc = correct / total if total > 0 else 0.0\n",
    "    return avg_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, criterion, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_probs = []\n",
    "    all_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(loader, desc=\"Val\", leave=False):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            out = model(images)\n",
    "            loss = criterion(out, masks)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(out).cpu().numpy().ravel()\n",
    "            labels = masks.cpu().numpy().ravel()\n",
    "\n",
    "            all_probs.append(probs)\n",
    "            all_true.append(labels)\n",
    "\n",
    "    avg_loss = running_loss / max(1, len(loader))\n",
    "    if all_probs:\n",
    "        y_prob = np.concatenate(all_probs)\n",
    "        y_true = np.concatenate(all_true)\n",
    "        metrics = compute_pixel_metrics(y_true, y_prob, threshold=threshold)\n",
    "    else:\n",
    "        y_prob = np.array([])\n",
    "        y_true = np.array([])\n",
    "        metrics = compute_pixel_metrics(y_true, y_prob, threshold=threshold)\n",
    "\n",
    "    return avg_loss, metrics, y_true, y_prob\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main fine-tune routine\n",
    "# ----------------------------\n",
    "\n",
    "def main():\n",
    "    # pick pretrained model\n",
    "    pretrained_path = choose_file(\"Select pretrained PoroDet model (.pth)\", \"*.pth\")\n",
    "    if not pretrained_path:\n",
    "        print(\"No model selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # pick new data\n",
    "    data_dir = choose_dir(\"Select folder with NEW TEM images and masks\")\n",
    "    if not data_dir:\n",
    "        print(\"No data folder selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # pick output folder\n",
    "    out_root = choose_dir(\"Select output folder for fine-tuning results\")\n",
    "    if not out_root:\n",
    "        print(\"No output folder selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_dir = os.path.join(out_root, f\"porodet_finetune_{run_id}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(f\"\\nOutputs will be saved in:\\n  {out_dir}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "    # dataset\n",
    "    dataset = NanoporeDataset(data_dir)\n",
    "    if len(dataset) == 0:\n",
    "        print(\"No valid image/mask pairs found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # simple 80/20 split\n",
    "    n_total = len(dataset)\n",
    "    n_train = int(0.8 * n_total)\n",
    "    n_val = n_total - n_train\n",
    "    train_set, val_set = torch.utils.data.random_split(\n",
    "        dataset,\n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "    print(f\"Train images: {len(train_set)}, Val images: {len(val_set)}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    # model + optimiser\n",
    "    model = load_pretrained_model(pretrained_path, device)\n",
    "\n",
    "    if freeze_encoder:\n",
    "        freeze_encoder_part(model)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    no_improve = 0\n",
    "\n",
    "    # for logging\n",
    "    epochs_list = []\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_precs = []\n",
    "    val_recs = []\n",
    "    val_f1s = []\n",
    "    val_ious = []\n",
    "    val_dices = []\n",
    "    val_pr_aucs = []\n",
    "    val_roc_aucs = []\n",
    "\n",
    "    last_y_true = None\n",
    "    last_y_prob = None\n",
    "\n",
    "    print(\"\\nStarting fine-tuning...\")\n",
    "    print(f\"  epochs        : {epochs}\")\n",
    "    print(f\"  learning rate : {learning_rate}\")\n",
    "    print(f\"  weight decay  : {weight_decay}\")\n",
    "    print(f\"  freeze encoder: {freeze_encoder}\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        val_loss, val_metrics, y_true, y_prob = eval_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # store last epoch preds for PR/ROC plots\n",
    "        last_y_true = y_true\n",
    "        last_y_prob = y_prob\n",
    "\n",
    "        epochs_list.append(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_metrics[\"accuracy\"])\n",
    "        val_precs.append(val_metrics[\"precision\"])\n",
    "        val_recs.append(val_metrics[\"recall\"])\n",
    "        val_f1s.append(val_metrics[\"f1\"])\n",
    "        val_ious.append(val_metrics[\"iou\"])\n",
    "        val_dices.append(val_metrics[\"dice\"])\n",
    "        val_pr_aucs.append(val_metrics[\"pr_auc\"])\n",
    "        val_roc_aucs.append(val_metrics[\"roc_auc\"])\n",
    "\n",
    "        print(f\"  train loss: {train_loss:.4f} | train acc: {train_acc:.4f}\")\n",
    "        print(\n",
    "            \"  val   loss: {:.4f} | val acc: {:.4f} | prec: {:.3f} | \"\n",
    "            \"rec: {:.3f} | F1: {:.3f} | IoU: {:.3f} | Dice: {:.3f} | \"\n",
    "            \"PR-AUC: {:.3f} | ROC-AUC: {:.3f}\".format(\n",
    "                val_loss,\n",
    "                val_metrics[\"accuracy\"],\n",
    "                val_metrics[\"precision\"],\n",
    "                val_metrics[\"recall\"],\n",
    "                val_metrics[\"f1\"],\n",
    "                val_metrics[\"iou\"],\n",
    "                val_metrics[\"dice\"],\n",
    "                val_metrics[\"pr_auc\"],\n",
    "                val_metrics[\"roc_auc\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # always save \"last epoch\"\n",
    "        last_path = os.path.join(out_dir, \"finetuned_last_epoch.pth\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"finetuned_from\": os.path.basename(pretrained_path),\n",
    "            },\n",
    "            last_path,\n",
    "        )\n",
    "\n",
    "        # check for new best\n",
    "        if val_loss < best_val - 1e-5:\n",
    "            best_val = val_loss\n",
    "            no_improve = 0\n",
    "            best_path = os.path.join(out_dir, \"finetuned_best_model.pth\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"finetuned_from\": os.path.basename(pretrained_path),\n",
    "                },\n",
    "                best_path,\n",
    "            )\n",
    "            print(f\"  → New best model saved: {best_path}\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            print(f\"  → No improvement for {no_improve} epoch(s).\")\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch} epochs.\")\n",
    "            break\n",
    "\n",
    "    # ----------------------------\n",
    "    # Save metrics to CSV\n",
    "    # ----------------------------\n",
    "    import csv\n",
    "\n",
    "    metrics_csv = os.path.join(out_dir, \"finetune_metrics.csv\")\n",
    "    with open(metrics_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"train_accuracy\",\n",
    "            \"val_loss\",\n",
    "            \"val_accuracy\",\n",
    "            \"val_precision\",\n",
    "            \"val_recall\",\n",
    "            \"val_f1\",\n",
    "            \"val_iou\",\n",
    "            \"val_dice\",\n",
    "            \"val_pr_auc\",\n",
    "            \"val_roc_auc\",\n",
    "        ])\n",
    "        for i in range(len(epochs_list)):\n",
    "            writer.writerow([\n",
    "                epochs_list[i],\n",
    "                train_losses[i],\n",
    "                train_accs[i],\n",
    "                val_losses[i],\n",
    "                val_accs[i],\n",
    "                val_precs[i],\n",
    "                val_recs[i],\n",
    "                val_f1s[i],\n",
    "                val_ious[i],\n",
    "                val_dices[i],\n",
    "                val_pr_aucs[i],\n",
    "                val_roc_aucs[i],\n",
    "            ])\n",
    "    print(f\"\\nMetrics saved to:\\n  {metrics_csv}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Plots: loss + accuracy\n",
    "    # ----------------------------\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs_list, train_losses, label=\"train\")\n",
    "    plt.plot(epochs_list, val_losses, label=\"val\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    loss_plot = os.path.join(out_dir, \"loss_curves.png\")\n",
    "    plt.savefig(loss_plot, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs_list, train_accs, label=\"train\")\n",
    "    plt.plot(epochs_list, val_accs, label=\"val\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    acc_plot = os.path.join(out_dir, \"accuracy_curves.png\")\n",
    "    plt.savefig(acc_plot, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Loss curves saved to:\\n  {loss_plot}\")\n",
    "    print(f\"Accuracy curves saved to:\\n  {acc_plot}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # PR & ROC curves for last epoch\n",
    "    # ----------------------------\n",
    "    if last_y_true is not None and last_y_true.size > 0 and np.unique(last_y_true).size > 1:\n",
    "        # PR curve\n",
    "        precision, recall, _ = precision_recall_curve(last_y_true, last_y_prob)\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.step(recall, precision, where=\"post\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Validation PR curve (last epoch)\")\n",
    "        plt.tight_layout()\n",
    "        pr_plot = os.path.join(out_dir, \"pr_curve_last_epoch.png\")\n",
    "        plt.savefig(pr_plot, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(last_y_true, last_y_prob)\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1], \"--\")\n",
    "        plt.xlabel(\"False positive rate\")\n",
    "        plt.ylabel(\"True positive rate\")\n",
    "        plt.title(\"Validation ROC curve (last epoch)\")\n",
    "        plt.tight_layout()\n",
    "        roc_plot = os.path.join(out_dir, \"roc_curve_last_epoch.png\")\n",
    "        plt.savefig(roc_plot, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"PR curve saved to:\\n  {pr_plot}\")\n",
    "        print(f\"ROC curve saved to:\\n  {roc_plot}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping PR/ROC plots (validation set had only one class or no data).\")\n",
    "\n",
    "    print(\"\\nFine-tuning finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
