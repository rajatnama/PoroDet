{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting nanopore detection model training...\n",
      "Model checkpoints will be saved to: D:/Rajat/augmented_images\\nanopore_model_20250306_151818\n",
      "Using device: cuda\n",
      "Found 20 original images with augmentations\n",
      "Using 17 originals for training, 3 for validation\n",
      "Validation originals: ['Image_10' 'Image_7' 'Image_5']\n",
      "Training set contains 272 images\n",
      "Validation set contains 48 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ml_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training with anti-overfitting measures...\n",
      "Early stopping patience: 3\n",
      "Learning rate: 5e-05\n",
      "Weight decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 272/272 [14:40<00:00,  3.24s/it, loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.4445, Val Loss: 0.3981\n",
      "Saved new best model with validation loss: 0.3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 272/272 [12:23<00:00,  2.73s/it, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.2887, Val Loss: 0.2369\n",
      "Saved new best model with validation loss: 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 272/272 [12:19<00:00,  2.72s/it, loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.2272, Val Loss: 0.2164\n",
      "Saved new best model with validation loss: 0.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 272/272 [14:06<00:00,  3.11s/it, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.1841, Val Loss: 0.1442\n",
      "Saved new best model with validation loss: 0.1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 272/272 [12:36<00:00,  2.78s/it, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.1528, Val Loss: 0.1345\n",
      "Saved new best model with validation loss: 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 272/272 [13:11<00:00,  2.91s/it, loss=0.109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.1287, Val Loss: 0.3152 - WARNING: Potential overfitting detected!\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 272/272 [12:31<00:00,  2.76s/it, loss=0.134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.1108, Val Loss: 0.0948\n",
      "Saved new best model with validation loss: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 272/272 [19:04<00:00,  4.21s/it, loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0948, Val Loss: 0.1216\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 272/272 [16:56<00:00,  3.74s/it, loss=0.069] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0836, Val Loss: 0.0666\n",
      "Saved new best model with validation loss: 0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 272/272 [17:36<00:00,  3.89s/it, loss=0.0624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0748, Val Loss: 0.0603\n",
      "Saved new best model with validation loss: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 272/272 [30:16<00:00,  6.68s/it, loss=0.0471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0675, Val Loss: 0.0509\n",
      "Saved new best model with validation loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 272/272 [14:28<00:00,  3.19s/it, loss=0.0513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0617, Val Loss: 0.0456\n",
      "Saved new best model with validation loss: 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 272/272 [13:40<00:00,  3.02s/it, loss=0.0576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.0563, Val Loss: 0.0461\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 272/272 [13:59<00:00,  3.09s/it, loss=0.0291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.0517, Val Loss: 0.0479\n",
      "Validation loss did not improve. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 272/272 [37:11<00:00,  8.20s/it, loss=0.0486]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.0477, Val Loss: 0.0747 - WARNING: Potential overfitting detected!\n",
      "Validation loss did not improve. Counter: 3/3\n",
      "Early stopping triggered after 15 epochs\n",
      "\n",
      "Training complete. Final model saved to: D:/Rajat/augmented_images\\nanopore_model_20250306_151818\\final_model.pth\n"
     ]
    }
   ],
   "source": [
    "#TEM nanopore detection with Anti-overfitting measures (without all the bells and whistles)\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate),  # Add dropout for regularization\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = DoubleConv(in_channels, 64, dropout_rate)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128, dropout_rate)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256, dropout_rate)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512, dropout_rate)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024, dropout_rate)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512, dropout_rate)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256, dropout_rate)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128, dropout_rate)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64, dropout_rate)\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.conv1(x)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        \n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        \n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "        \n",
    "        conv4 = self.conv4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "        \n",
    "        conv5 = self.conv5(pool4)\n",
    "        \n",
    "        # Decoder\n",
    "        up6 = self.up6(conv5)\n",
    "        merge6 = torch.cat([up6, conv4], dim=1)\n",
    "        conv6 = self.conv6(merge6)\n",
    "        \n",
    "        up7 = self.up7(conv6)\n",
    "        merge7 = torch.cat([up7, conv3], dim=1)\n",
    "        conv7 = self.conv7(merge7)\n",
    "        \n",
    "        up8 = self.up8(conv7)\n",
    "        merge8 = torch.cat([up8, conv2], dim=1)\n",
    "        conv8 = self.conv8(merge8)\n",
    "        \n",
    "        up9 = self.up9(conv8)\n",
    "        merge9 = torch.cat([up9, conv1], dim=1)\n",
    "        conv9 = self.conv9(merge9)\n",
    "        \n",
    "        conv10 = self.conv10(conv9)\n",
    "        return conv10\n",
    "\n",
    "def get_original_and_augmented_groups(data_dir):\n",
    "    \"\"\"Group files by original images and their augmentations\"\"\"\n",
    "    all_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.tif')])\n",
    "    \n",
    "    # Group by original image\n",
    "    original_groups = {}\n",
    "    for file in all_files:\n",
    "        if \"_aug_\" in file:\n",
    "            original_name = file.split(\"_aug_\")[0]\n",
    "            aug_num = int(file.split(\"_aug_\")[1].split('.')[0])\n",
    "            \n",
    "            if original_name not in original_groups:\n",
    "                original_groups[original_name] = []\n",
    "            original_groups[original_name].append((file, aug_num))\n",
    "    \n",
    "    # Sort augmentations within each group\n",
    "    for orig in original_groups:\n",
    "        original_groups[orig].sort(key=lambda x: x[1])\n",
    "    \n",
    "    return original_groups\n",
    "\n",
    "class NanoporeDataset(Dataset):\n",
    "    def __init__(self, data_dir, original_images, is_validation=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.is_validation = is_validation\n",
    "        \n",
    "        # Get all TIF files and their corresponding masks\n",
    "        all_files = sorted(os.listdir(data_dir))\n",
    "        self.image_files = []\n",
    "        \n",
    "        for file in all_files:\n",
    "            if file.endswith('.tif'):\n",
    "                # Check if file is from our selected original images\n",
    "                original_name = file.split(\"_aug_\")[0] if \"_aug_\" in file else file.replace('.tif', '')\n",
    "                \n",
    "                if original_name in original_images:\n",
    "                    mask_file = file.replace('.tif', '_mask.png')\n",
    "                    \n",
    "                    # Only include if mask exists\n",
    "                    if mask_file in all_files:\n",
    "                        self.image_files.append(file)\n",
    "        \n",
    "        print(f\"{'Validation' if is_validation else 'Training'} set contains {len(self.image_files)} images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Get image and mask paths\n",
    "            img_path = os.path.join(self.data_dir, self.image_files[idx])\n",
    "            mask_path = os.path.join(self.data_dir, self.image_files[idx].replace('.tif', '_mask.png'))\n",
    "            \n",
    "            # Read images\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if image is None or mask is None:\n",
    "                raise ValueError(f\"Failed to read image or mask: {self.image_files[idx]}\")\n",
    "            \n",
    "            # Resize to 1024x1024\n",
    "            image = cv2.resize(image, (1024, 1024), interpolation=cv2.INTER_AREA)\n",
    "            mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            # Normalize\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            mask = mask.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Convert to tensors\n",
    "            image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
    "            mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "            \n",
    "            return image, mask\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            # Return a placeholder to avoid crashing\n",
    "            # In practice, could use a random image from the dataset\n",
    "            placeholder = torch.zeros((1, 1024, 1024), dtype=torch.float32)\n",
    "            return placeholder, placeholder\n",
    "\n",
    "def check_overfitting(train_loss, val_loss, threshold=0.3):\n",
    "    \"\"\"Check if model is overfitting based on train/val loss gap\"\"\"\n",
    "    if val_loss > 0 and train_loss < val_loss * (1 - threshold):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def train_nanopore_detector(data_dir, output_dir, \n",
    "                          batch_size=1, \n",
    "                          epochs=30,\n",
    "                          learning_rate=5e-5,\n",
    "                          patience=3,\n",
    "                          weight_decay=1e-4):\n",
    "    \"\"\"Train nanopore detector with anti-overfitting measures\"\"\"\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Get image groups\n",
    "    original_groups = get_original_and_augmented_groups(data_dir)\n",
    "    original_images = list(original_groups.keys())\n",
    "    print(f\"Found {len(original_images)} original images with augmentations\")\n",
    "    \n",
    "    # Split into train/val by original images\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    val_size = max(2, int(len(original_images) * 0.15))  # 15% for validation\n",
    "    val_originals = np.random.choice(original_images, size=val_size, replace=False)\n",
    "    train_originals = [img for img in original_images if img not in val_originals]\n",
    "    \n",
    "    print(f\"Using {len(train_originals)} originals for training, {len(val_originals)} for validation\")\n",
    "    print(f\"Validation originals: {val_originals}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = NanoporeDataset(data_dir, train_originals, is_validation=False)\n",
    "    val_dataset = NanoporeDataset(data_dir, val_originals, is_validation=True)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Create model with dropout\n",
    "    model = UNet(in_channels=1, out_channels=1, dropout_rate=0.2).to(device)\n",
    "    \n",
    "    # Loss and optimizer with weight decay\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Setup for training\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Create directory for visualizations\n",
    "    vis_dir = os.path.join(output_dir, 'visualizations')\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\nStarting training with anti-overfitting measures...\")\n",
    "    print(f\"Early stopping patience: {patience}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}') as pbar:\n",
    "                for batch_idx, (images, masks) in enumerate(pbar):\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    train_loss += loss.item()\n",
    "                    pbar.set_postfix({'loss': loss.item()})\n",
    "                    \n",
    "                    # Periodically clear cache\n",
    "                    if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # Save some validation predictions for visual inspection\n",
    "                    if epoch % 5 == 0 and val_loss == 0:  # First batch of every 5th epoch\n",
    "                        output_sigmoid = torch.sigmoid(outputs)\n",
    "                        for i in range(min(2, len(images))):\n",
    "                            # Create visualization\n",
    "                            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                            \n",
    "                            # Original image\n",
    "                            axes[0].imshow(images[i].cpu().numpy()[0], cmap='gray')\n",
    "                            axes[0].set_title('TEM Image')\n",
    "                            axes[0].axis('off')\n",
    "                            \n",
    "                            # Ground truth mask\n",
    "                            axes[1].imshow(masks[i].cpu().numpy()[0], cmap='gray')\n",
    "                            axes[1].set_title('True Mask')\n",
    "                            axes[1].axis('off')\n",
    "                            \n",
    "                            # Predicted mask\n",
    "                            axes[2].imshow(output_sigmoid[i].cpu().numpy()[0], cmap='gray')\n",
    "                            axes[2].set_title('Predicted Mask')\n",
    "                            axes[2].axis('off')\n",
    "                            \n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(os.path.join(vis_dir, f'epoch_{epoch}_sample_{i}.png'))\n",
    "                            plt.close()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            \n",
    "            # Check for overfitting\n",
    "            is_overfitting = check_overfitting(avg_train_loss, avg_val_loss)\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f'Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}', end='')\n",
    "            if is_overfitting:\n",
    "                print(' - WARNING: Potential overfitting detected!')\n",
    "            else:\n",
    "                print('')\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Save checkpoint every epoch\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss\n",
    "            }, os.path.join(output_dir, f'checkpoint_epoch_{epoch}.pth'))\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'val_loss': avg_val_loss\n",
    "                }, os.path.join(output_dir, 'best_model.pth'))\n",
    "                print(f'Saved new best model with validation loss: {best_val_loss:.4f}')\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                print(f'Validation loss did not improve. Counter: {early_stop_counter}/{patience}')\n",
    "                \n",
    "                if early_stop_counter >= patience:\n",
    "                    print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                    break\n",
    "            \n",
    "            # Clear GPU cache after each epoch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Plot train/val loss curves\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.savefig(os.path.join(output_dir, 'loss_curves.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {str(e)}\")\n",
    "        print(\"Saving emergency checkpoint...\")\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'emergency_save.pth'))\n",
    "        raise e\n",
    "\n",
    "def main():\n",
    "    # Setup UI for folder selection\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    data_dir = filedialog.askdirectory(title=\"Select Directory with TEM Images and Masks\")\n",
    "    \n",
    "    if not data_dir:\n",
    "        print(\"No directory selected. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_dir = os.path.join(data_dir, f'nanopore_model_{timestamp}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\nStarting nanopore detection model training...\")\n",
    "    print(f\"Model checkpoints will be saved to: {output_dir}\")\n",
    "    \n",
    "    try:\n",
    "        model = train_nanopore_detector(data_dir, output_dir)\n",
    "        \n",
    "        # Save final model\n",
    "        final_model_path = os.path.join(output_dir, 'final_model.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        print(f\"\\nTraining complete. Final model saved to: {final_model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Training failed with error: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory at failure: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting nanopore detection model training...\n",
      "Model checkpoints and outputs will be saved to: D:/Rajat/Nanoporosity/albumented_images\\nanopore_model_20251112_172446\n",
      "Using device: cuda\n",
      "Found 20 original images with augmentations\n",
      "Using 17 originals for training, 3 for validation\n",
      "Validation originals: ['Image_10', 'Image_7', 'Image_5']\n",
      "Training set contains 255 images\n",
      "Validation set contains 45 images\n",
      "\n",
      "Starting training with verbose metrics...\n",
      "Early stopping patience: 3\n",
      "Learning rate: 5e-05\n",
      "Weight decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [train]: 100%|██████████| 255/255 [23:06<00:00,  5.44s/it, loss=0.3197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.4157, Train Acc 0.9478 | Val Loss 0.9736, Val Acc 0.9526 | Val Prec 0.0984, Rec 0.6872, F1 0.1721, IoU 0.0942, Dice 0.1721 | PR-AUC 0.12096339361937276, ROC-AUC 0.9180450571939965\n",
      " - WARNING: Potential overfitting detected!\n",
      "Saved new best model (val loss 0.9736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [train]: 100%|██████████| 255/255 [21:36<00:00,  5.09s/it, loss=0.2320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.2762, Train Acc 0.9821 | Val Loss 0.2579, Val Acc 0.9897 | Val Prec 0.3639, Rec 0.5829, F1 0.4480, IoU 0.2887, Dice 0.4480 | PR-AUC 0.33087785811500287, ROC-AUC 0.9430279594422356\n",
      "Saved new best model (val loss 0.2579)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [train]: 100%|██████████| 255/255 [21:10<00:00,  4.98s/it, loss=0.1980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.2207, Train Acc 0.9831 | Val Loss 0.1778, Val Acc 0.9936 | Val Prec 0.5563, Rec 0.5326, F1 0.5442, IoU 0.3738, Dice 0.5442 | PR-AUC 0.5228139623833468, ROC-AUC 0.958017663409531\n",
      "Saved new best model (val loss 0.1778)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [train]: 100%|██████████| 255/255 [20:47<00:00,  4.89s/it, loss=0.1502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.1839, Train Acc 0.9833 | Val Loss 0.1529, Val Acc 0.9932 | Val Prec 0.5232, Rec 0.5621, F1 0.5420, IoU 0.3717, Dice 0.5420 | PR-AUC 0.528280430683488, ROC-AUC 0.9563666998425551\n",
      "Saved new best model (val loss 0.1529)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [train]: 100%|██████████| 255/255 [20:52<00:00,  4.91s/it, loss=0.1780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.1559, Train Acc 0.9836 | Val Loss 0.1285, Val Acc 0.9908 | Val Prec 0.4130, Rec 0.6587, F1 0.5077, IoU 0.3402, Dice 0.5077 | PR-AUC 0.5155693045012066, ROC-AUC 0.9683345574530089\n",
      "Saved new best model (val loss 0.1285)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [train]: 100%|██████████| 255/255 [19:49<00:00,  4.67s/it, loss=0.1232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.1341, Train Acc 0.9838 | Val Loss 0.1087, Val Acc 0.9938 | Val Prec 0.5716, Rec 0.5212, F1 0.5452, IoU 0.3748, Dice 0.5452 | PR-AUC 0.5281021567477429, ROC-AUC 0.9605293913031249\n",
      "Saved new best model (val loss 0.1087)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [train]: 100%|██████████| 255/255 [19:57<00:00,  4.70s/it, loss=0.0929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.1168, Train Acc 0.9841 | Val Loss 0.1515, Val Acc 0.9887 | Val Prec 0.3575, Rec 0.7166, F1 0.4770, IoU 0.3132, Dice 0.4770 | PR-AUC 0.40967357514639, ROC-AUC 0.963206403842076\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [train]: 100%|██████████| 255/255 [20:08<00:00,  4.74s/it, loss=0.1348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.1036, Train Acc 0.9842 | Val Loss 0.0817, Val Acc 0.9903 | Val Prec 0.3974, Rec 0.6800, F1 0.5016, IoU 0.3348, Dice 0.5016 | PR-AUC 0.5058390360169867, ROC-AUC 0.97523099837765\n",
      "Saved new best model (val loss 0.0817)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [train]: 100%|██████████| 255/255 [26:51<00:00,  6.32s/it, loss=0.0755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0922, Train Acc 0.9843 | Val Loss 0.0711, Val Acc 0.9924 | Val Prec 0.4785, Rec 0.6621, F1 0.5555, IoU 0.3846, Dice 0.5555 | PR-AUC 0.5756530978431165, ROC-AUC 0.9762750694087294\n",
      "Saved new best model (val loss 0.0711)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [train]: 100%|██████████| 255/255 [23:27<00:00,  5.52s/it, loss=0.0720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0824, Train Acc 0.9847 | Val Loss 0.0632, Val Acc 0.9924 | Val Prec 0.4774, Rec 0.6773, F1 0.5600, IoU 0.3889, Dice 0.5600 | PR-AUC 0.5880964991629962, ROC-AUC 0.978554399206711\n",
      "Saved new best model (val loss 0.0632)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [train]: 100%|██████████| 255/255 [22:02<00:00,  5.19s/it, loss=0.0549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0749, Train Acc 0.9850 | Val Loss 0.0583, Val Acc 0.9911 | Val Prec 0.4285, Rec 0.7166, F1 0.5363, IoU 0.3664, Dice 0.5363 | PR-AUC 0.5791546339015351, ROC-AUC 0.9795814795641707\n",
      "Saved new best model (val loss 0.0583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [train]: 100%|██████████| 255/255 [22:06<00:00,  5.20s/it, loss=0.0719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0695, Train Acc 0.9849 | Val Loss 0.0516, Val Acc 0.9904 | Val Prec 0.4053, Rec 0.7268, F1 0.5204, IoU 0.3517, Dice 0.5204 | PR-AUC 0.590789499401029, ROC-AUC 0.9777933120287408\n",
      "Saved new best model (val loss 0.0516)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [train]: 100%|██████████| 255/255 [22:24<00:00,  5.27s/it, loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0641, Train Acc 0.9853 | Val Loss 0.0487, Val Acc 0.9924 | Val Prec 0.4805, Rec 0.6756, F1 0.5616, IoU 0.3904, Dice 0.5616 | PR-AUC 0.5898919179163282, ROC-AUC 0.9819114193271943\n",
      "Saved new best model (val loss 0.0487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [train]: 100%|██████████| 255/255 [22:51<00:00,  5.38s/it, loss=0.0522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0596, Train Acc 0.9856 | Val Loss 0.0398, Val Acc 0.9922 | Val Prec 0.4702, Rec 0.6882, F1 0.5587, IoU 0.3876, Dice 0.5587 | PR-AUC 0.595173944572817, ROC-AUC 0.9815957254220865\n",
      "Saved new best model (val loss 0.0398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [train]: 100%|██████████| 255/255 [22:16<00:00,  5.24s/it, loss=0.0598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0567, Train Acc 0.9855 | Val Loss 0.0597, Val Acc 0.9834 | Val Prec 0.2761, Rec 0.8087, F1 0.4117, IoU 0.2592, Dice 0.4117 | PR-AUC 0.5593558593045749, ROC-AUC 0.9802682623392329\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [train]: 100%|██████████| 255/255 [22:53<00:00,  5.39s/it, loss=0.0399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss 0.0538, Train Acc 0.9858 | Val Loss 0.0428, Val Acc 0.9895 | Val Prec 0.3790, Rec 0.7175, F1 0.4960, IoU 0.3298, Dice 0.4960 | PR-AUC 0.5179639582053689, ROC-AUC 0.9730546860839561\n",
      "Validation loss did not improve. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [train]: 100%|██████████| 255/255 [23:29<00:00,  5.53s/it, loss=0.0239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss 0.0517, Train Acc 0.9858 | Val Loss 0.0368, Val Acc 0.9916 | Val Prec 0.4448, Rec 0.7027, F1 0.5448, IoU 0.3743, Dice 0.5448 | PR-AUC 0.5766557232264454, ROC-AUC 0.9833429230059626\n",
      "Saved new best model (val loss 0.0368)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [train]: 100%|██████████| 255/255 [25:27<00:00,  5.99s/it, loss=0.0922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss 0.0493, Train Acc 0.9861 | Val Loss 0.0399, Val Acc 0.9908 | Val Prec 0.4182, Rec 0.7268, F1 0.5309, IoU 0.3614, Dice 0.5309 | PR-AUC 0.5625363529432955, ROC-AUC 0.983569873039802\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [train]: 100%|██████████| 255/255 [23:17<00:00,  5.48s/it, loss=0.0451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss 0.0481, Train Acc 0.9859 | Val Loss 0.0317, Val Acc 0.9915 | Val Prec 0.4411, Rec 0.7168, F1 0.5461, IoU 0.3756, Dice 0.5461 | PR-AUC 0.6062174846372399, ROC-AUC 0.9835252111894168\n",
      "Saved new best model (val loss 0.0317)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [train]: 100%|██████████| 255/255 [22:32<00:00,  5.30s/it, loss=0.0303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss 0.0464, Train Acc 0.9861 | Val Loss 0.0391, Val Acc 0.9902 | Val Prec 0.3971, Rec 0.7082, F1 0.5089, IoU 0.3413, Dice 0.5089 | PR-AUC 0.47968833520173026, ROC-AUC 0.9793505435510342\n",
      "Validation loss did not improve. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [train]: 100%|██████████| 255/255 [23:49<00:00,  5.61s/it, loss=0.1015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss 0.0447, Train Acc 0.9864 | Val Loss 0.0529, Val Acc 0.9882 | Val Prec 0.3500, Rec 0.7518, F1 0.4776, IoU 0.3138, Dice 0.4776 | PR-AUC 0.4489661367674278, ROC-AUC 0.9783012612770149\n",
      "Validation loss did not improve. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [train]: 100%|██████████| 255/255 [23:32<00:00,  5.54s/it, loss=0.0148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss 0.0434, Train Acc 0.9865 | Val Loss 0.0333, Val Acc 0.9907 | Val Prec 0.4157, Rec 0.7366, F1 0.5315, IoU 0.3619, Dice 0.5315 | PR-AUC 0.5398227986079676, ROC-AUC 0.9818984711088902\n",
      "Validation loss did not improve. Counter: 3/3\n",
      "Early stopping triggered after 22 epochs\n",
      "Training finished. Final model saved to: D:/Rajat/Nanoporosity/albumented_images\\nanopore_model_20251112_172446\\final_model.pth\n",
      "Saved metrics CSV to: D:/Rajat/Nanoporosity/albumented_images\\nanopore_model_20251112_172446\\metrics.csv\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#Final model with accuracy values!/usr/bin/env python3\n",
    "\"\"\"\n",
    "TEM nanopore detector training script with verbose metrics and plotting.\n",
    "Copy-paste this file and run. Uses a GUI folder picker to choose the dataset directory.\n",
    "\n",
    "Expected dataset layout: For each image .tif there is a corresponding mask named\n",
    "    <image_name>_mask.png\n",
    "Augmented files with suffix \"_aug_<n>.tif\" are grouped by original image name.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# sklearn metrics\n",
    "try:\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score,\n",
    "        average_precision_score,\n",
    "        precision_recall_curve,\n",
    "        roc_curve,\n",
    "        auc,\n",
    "        f1_score,\n",
    "        jaccard_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise ImportError(\"scikit-learn is required for metrics. Install it with `pip install scikit-learn`.\") from e\n",
    "\n",
    "# ---------------------------\n",
    "# Model: UNet + DoubleConv\n",
    "# ---------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = DoubleConv(in_channels, 64, dropout_rate)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128, dropout_rate)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256, dropout_rate)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512, dropout_rate)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024, dropout_rate)\n",
    "\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512, dropout_rate)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256, dropout_rate)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128, dropout_rate)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64, dropout_rate)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "\n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "\n",
    "        conv4 = self.conv4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "\n",
    "        conv5 = self.conv5(pool4)\n",
    "\n",
    "        up6 = self.up6(conv5)\n",
    "        merge6 = torch.cat([up6, conv4], dim=1)\n",
    "        conv6 = self.conv6(merge6)\n",
    "\n",
    "        up7 = self.up7(conv6)\n",
    "        merge7 = torch.cat([up7, conv3], dim=1)\n",
    "        conv7 = self.conv7(merge7)\n",
    "\n",
    "        up8 = self.up8(conv7)\n",
    "        merge8 = torch.cat([up8, conv2], dim=1)\n",
    "        conv8 = self.conv8(merge8)\n",
    "\n",
    "        up9 = self.up9(conv8)\n",
    "        merge9 = torch.cat([up9, conv1], dim=1)\n",
    "        conv9 = self.conv9(merge9)\n",
    "\n",
    "        conv10 = self.conv10(conv9)\n",
    "        return conv10\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities and Dataset\n",
    "# ---------------------------\n",
    "def get_original_and_augmented_groups(data_dir):\n",
    "    \"\"\"Group files by original images and their augmentations\"\"\"\n",
    "    # consider .tif images only\n",
    "    all_files = sorted([f for f in os.listdir(data_dir) if f.lower().endswith('.tif')])\n",
    "    original_groups = {}\n",
    "    for file in all_files:\n",
    "        if \"_aug_\" in file:\n",
    "            original_name = file.split(\"_aug_\")[0]\n",
    "            try:\n",
    "                aug_num = int(file.split(\"_aug_\")[1].split('.')[0])\n",
    "            except Exception:\n",
    "                aug_num = 0\n",
    "            original_groups.setdefault(original_name, []).append((file, aug_num))\n",
    "        else:\n",
    "            # also include originals even if no aug\n",
    "            original_groups.setdefault(file.replace('.tif',''), [])\n",
    "    # sort augmentation lists\n",
    "    for k in list(original_groups.keys()):\n",
    "        original_groups[k] = sorted(original_groups[k], key=lambda x: x[1])\n",
    "    return original_groups\n",
    "\n",
    "class NanoporeDataset(Dataset):\n",
    "    def __init__(self, data_dir, original_images, is_validation=False, target_size=(1024,1024)):\n",
    "        self.data_dir = data_dir\n",
    "        self.is_validation = is_validation\n",
    "        self.target_size = target_size\n",
    "\n",
    "        all_files = sorted(os.listdir(data_dir))\n",
    "        image_files = []\n",
    "        for file in all_files:\n",
    "            if file.lower().endswith('.tif'):\n",
    "                original_name = file.split(\"_aug_\")[0] if \"_aug_\" in file else file.replace('.tif','')\n",
    "                if original_name in original_images:\n",
    "                    mask_file = file.replace('.tif', '_mask.png')\n",
    "                    if mask_file in all_files:\n",
    "                        image_files.append(file)\n",
    "        self.image_files = image_files\n",
    "        print(f\"{'Validation' if is_validation else 'Training'} set contains {len(self.image_files)} images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.image_files[idx]\n",
    "            img_path = os.path.join(self.data_dir, img_name)\n",
    "            mask_path = os.path.join(self.data_dir, img_name.replace('.tif', '_mask.png'))\n",
    "\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is None or mask is None:\n",
    "                raise ValueError(f\"Could not read {img_name} or mask\")\n",
    "\n",
    "            image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "            mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            mask = (mask.astype(np.float32) / 255.0)  # may be 0/255 or 0/1\n",
    "\n",
    "            image = torch.from_numpy(image).unsqueeze(0)\n",
    "            mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "            return image, mask\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {e}\")\n",
    "            placeholder = torch.zeros((1, 1024, 1024), dtype=torch.float32)\n",
    "            return placeholder, placeholder\n",
    "\n",
    "# ---------------------------\n",
    "# Metric helpers\n",
    "# ---------------------------\n",
    "def dice_coeff(preds_bool, targets_bool, eps=1e-7):\n",
    "    preds = preds_bool.astype(np.uint8)\n",
    "    targets = targets_bool.astype(np.uint8)\n",
    "    intersection = (preds & targets).sum()\n",
    "    return (2. * intersection + eps) / (preds.sum() + targets.sum() + eps)\n",
    "\n",
    "def iou_score_np(preds_bool, targets_bool, eps=1e-7):\n",
    "    preds = preds_bool.astype(np.uint8)\n",
    "    targets = targets_bool.astype(np.uint8)\n",
    "    intersection = (preds & targets).sum()\n",
    "    union = (preds | targets).sum()\n",
    "    return (intersection + eps) / (union + eps)\n",
    "\n",
    "def check_overfitting(train_loss, val_loss, threshold=0.3):\n",
    "    \"\"\"Check if model is overfitting based on train/val loss gap\"\"\"\n",
    "    if val_loss > 0 and train_loss < val_loss * (1 - threshold):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ---------------------------\n",
    "# Training function (fixed: detach before numpy conversions)\n",
    "# ---------------------------\n",
    "def train_nanopore_detector(data_dir, output_dir,\n",
    "                            batch_size=1,\n",
    "                            epochs=30,\n",
    "                            learning_rate=5e-5,\n",
    "                            patience=3,\n",
    "                            weight_decay=1e-4,\n",
    "                            prob_threshold=0.5,\n",
    "                            resize_to=(1024,1024)):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    original_groups = get_original_and_augmented_groups(data_dir)\n",
    "    original_images = list(original_groups.keys())\n",
    "    print(f\"Found {len(original_images)} original images with augmentations\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    val_size = max(2, int(len(original_images) * 0.15))\n",
    "    val_originals = np.random.choice(original_images, size=val_size, replace=False).tolist()\n",
    "    train_originals = [img for img in original_images if img not in val_originals]\n",
    "\n",
    "    print(f\"Using {len(train_originals)} originals for training, {len(val_originals)} for validation\")\n",
    "    print(f\"Validation originals: {val_originals}\")\n",
    "\n",
    "    train_dataset = NanoporeDataset(data_dir, train_originals, is_validation=False, target_size=resize_to)\n",
    "    val_dataset = NanoporeDataset(data_dir, val_originals, is_validation=True, target_size=resize_to)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,\n",
    "                              pin_memory=True if torch.cuda.is_available() else False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0,\n",
    "                            pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "    model = UNet(in_channels=1, out_channels=1, dropout_rate=0.2).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'val_f1': [],\n",
    "        'val_iou': [],\n",
    "        'val_dice': [],\n",
    "        'val_pr_auc': [],\n",
    "        'val_roc_auc': []\n",
    "    }\n",
    "\n",
    "    vis_dir = os.path.join(output_dir, 'visualizations')\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nStarting training with verbose metrics...\")\n",
    "    print(f\"Early stopping patience: {patience}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            # -----------------------\n",
    "            # Training (compute train loss + train accuracy)\n",
    "            # -----------------------\n",
    "            model.train()\n",
    "            running_train_loss = 0.0\n",
    "            train_probs_list = []\n",
    "            train_targets_list = []\n",
    "\n",
    "            with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [train]\") as pbar:\n",
    "                for images, masks in pbar:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_train_loss += loss.item()\n",
    "                    # collect probabilities and targets for train accuracy\n",
    "                    probs = torch.sigmoid(outputs).detach().cpu().numpy()  # <-- detach here\n",
    "                    targets = masks.detach().cpu().numpy()\n",
    "                    train_probs_list.append(probs.reshape(-1))\n",
    "                    train_targets_list.append(targets.reshape(-1))\n",
    "\n",
    "                    pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "            avg_train_loss = running_train_loss / max(1, len(train_loader))\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "            if len(train_probs_list) > 0 and len(train_targets_list) > 0:\n",
    "                all_train_probs = np.concatenate(train_probs_list)\n",
    "                all_train_targets = np.concatenate(train_targets_list)\n",
    "                train_bin_preds = (all_train_probs >= prob_threshold).astype(np.uint8)\n",
    "                train_bin_targets = (all_train_targets >= 0.5).astype(np.uint8)\n",
    "                train_accuracy = (train_bin_preds == train_bin_targets).mean()\n",
    "            else:\n",
    "                train_accuracy = float('nan')\n",
    "\n",
    "            history['train_accuracy'].append(float(train_accuracy))\n",
    "\n",
    "            # -----------------------\n",
    "            # Validation\n",
    "            # -----------------------\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            val_probs_list = []\n",
    "            val_targets_list = []\n",
    "            vis_saved = False\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, masks) in enumerate(val_loader):\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    running_val_loss += loss.item()\n",
    "\n",
    "                    probs = torch.sigmoid(outputs).detach().cpu().numpy()  # <-- detach here\n",
    "                    targets = masks.detach().cpu().numpy()\n",
    "                    val_probs_list.append(probs.reshape(-1))\n",
    "                    val_targets_list.append(targets.reshape(-1))\n",
    "\n",
    "                    if (epoch % 5 == 0) and (not vis_saved):\n",
    "                        for i in range(min(2, images.size(0))):\n",
    "                            img_np = images[i].detach().cpu().numpy()[0]\n",
    "                            gt_np = targets[i][0]\n",
    "                            pred_np = probs[i][0]\n",
    "                            fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "                            axes[0].imshow(img_np, cmap='gray'); axes[0].set_title('TEM'); axes[0].axis('off')\n",
    "                            axes[1].imshow(gt_np, cmap='gray'); axes[1].set_title('Mask'); axes[1].axis('off')\n",
    "                            axes[2].imshow(pred_np, cmap='gray'); axes[2].set_title('Pred Prob'); axes[2].axis('off')\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(os.path.join(vis_dir, f'epoch_{epoch}_val_sample_{i}.png'))\n",
    "                            plt.close()\n",
    "                        vis_saved = True\n",
    "\n",
    "            avg_val_loss = running_val_loss / max(1, len(val_loader))\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "            if len(val_probs_list) > 0 and len(val_targets_list) > 0:\n",
    "                all_val_probs = np.concatenate(val_probs_list)\n",
    "                all_val_targets = np.concatenate(val_targets_list)\n",
    "                val_bin_preds = (all_val_probs >= prob_threshold).astype(np.uint8)\n",
    "                val_bin_targets = (all_val_targets >= 0.5).astype(np.uint8)\n",
    "\n",
    "                val_accuracy = (val_bin_preds == val_bin_targets).mean()\n",
    "                prec = precision_score(val_bin_targets, val_bin_preds, zero_division=0)\n",
    "                rec = recall_score(val_bin_targets, val_bin_preds, zero_division=0)\n",
    "                f1 = f1_score(val_bin_targets, val_bin_preds, zero_division=0)\n",
    "                try:\n",
    "                    iou = jaccard_score(val_bin_targets, val_bin_preds, zero_division=0)\n",
    "                except Exception:\n",
    "                    iou = iou_score_np(val_bin_preds.astype(bool), val_bin_targets.astype(bool))\n",
    "                dice = dice_coeff(val_bin_preds.astype(bool), val_bin_targets.astype(bool))\n",
    "                try:\n",
    "                    pr_auc = average_precision_score(val_bin_targets, all_val_probs)\n",
    "                except Exception:\n",
    "                    pr_auc = float('nan')\n",
    "                has_pos = val_bin_targets.sum() > 0\n",
    "                has_neg = (val_bin_targets.size - val_bin_targets.sum()) > 0\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(val_bin_targets, all_val_probs) if (has_pos and has_neg) else float('nan')\n",
    "                except Exception:\n",
    "                    roc_auc = float('nan')\n",
    "            else:\n",
    "                val_accuracy = prec = rec = f1 = iou = dice = pr_auc = roc_auc = float('nan')\n",
    "                all_val_probs = np.array([])\n",
    "                all_val_targets = np.array([])\n",
    "\n",
    "            history['val_accuracy'].append(float(val_accuracy))\n",
    "            history['val_precision'].append(float(prec))\n",
    "            history['val_recall'].append(float(rec))\n",
    "            history['val_f1'].append(float(f1))\n",
    "            history['val_iou'].append(float(iou))\n",
    "            history['val_dice'].append(float(dice))\n",
    "            history['val_pr_auc'].append(float(pr_auc) if not np.isnan(pr_auc) else None)\n",
    "            history['val_roc_auc'].append(float(roc_auc) if not np.isnan(roc_auc) else None)\n",
    "\n",
    "            # -----------------------\n",
    "            # Print epoch summary (both train & val loss + train & val accuracy)\n",
    "            # -----------------------\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}: \"\n",
    "                f\"Train Loss {avg_train_loss:.4f}, Train Acc {train_accuracy:.4f} | \"\n",
    "                f\"Val Loss {avg_val_loss:.4f}, Val Acc {val_accuracy:.4f} | \"\n",
    "                f\"Val Prec {prec:.4f}, Rec {rec:.4f}, F1 {f1:.4f}, IoU {iou:.4f}, Dice {dice:.4f} | \"\n",
    "                f\"PR-AUC {pr_auc if not np.isnan(pr_auc) else 'NA'}, ROC-AUC {roc_auc if not np.isnan(roc_auc) else 'NA'}\"\n",
    "            )\n",
    "\n",
    "            # Overfitting check\n",
    "            if check_overfitting(avg_train_loss, avg_val_loss):\n",
    "                print(\" - WARNING: Potential overfitting detected!\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'val_accuracy': val_accuracy\n",
    "            }, os.path.join(output_dir, f'checkpoint_epoch_{epoch}.pth'))\n",
    "\n",
    "            # Save best\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': avg_train_loss,\n",
    "                    'train_accuracy': train_accuracy,\n",
    "                    'val_loss': avg_val_loss,\n",
    "                    'val_accuracy': val_accuracy\n",
    "                }, os.path.join(output_dir, 'best_model.pth'))\n",
    "                print(f\"Saved new best model (val loss {best_val_loss:.4f})\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                print(f\"Validation loss did not improve. Counter: {early_stop_counter}/{patience}\")\n",
    "                if early_stop_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step(avg_val_loss)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # Save final model and metrics CSV (includes train_accuracy now)\n",
    "        final_model_path = os.path.join(output_dir, 'final_model.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        print(f\"Training finished. Final model saved to: {final_model_path}\")\n",
    "\n",
    "        csv_path = os.path.join(output_dir, 'metrics.csv')\n",
    "        with open(csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            header = ['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall',\n",
    "                      'val_f1', 'val_iou', 'val_dice', 'val_pr_auc', 'val_roc_auc']\n",
    "            writer.writerow(header)\n",
    "            for i in range(len(history['train_loss'])):\n",
    "                row = [\n",
    "                    i+1,\n",
    "                    history['train_loss'][i],\n",
    "                    history['train_accuracy'][i] if i < len(history['train_accuracy']) else '',\n",
    "                    history['val_loss'][i] if i < len(history['val_loss']) else '',\n",
    "                    history['val_accuracy'][i] if i < len(history['val_accuracy']) else '',\n",
    "                    history['val_precision'][i] if i < len(history['val_precision']) else '',\n",
    "                    history['val_recall'][i] if i < len(history['val_recall']) else '',\n",
    "                    history['val_f1'][i] if i < len(history['val_f1']) else '',\n",
    "                    history['val_iou'][i] if i < len(history['val_iou']) else '',\n",
    "                    history['val_dice'][i] if i < len(history['val_dice']) else '',\n",
    "                    history['val_pr_auc'][i] if i < len(history['val_pr_auc']) else '',\n",
    "                    history['val_roc_auc'][i] if i < len(history['val_roc_auc']) else ''\n",
    "                ]\n",
    "                writer.writerow(row)\n",
    "        print(f\"Saved metrics CSV to: {csv_path}\")\n",
    "\n",
    "        # Plot loss curves (train + val)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Val Loss')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss curves')\n",
    "        plt.savefig(os.path.join(output_dir, 'loss_curves.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Plot accuracy curves (train + val)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(history['train_accuracy'], label='Train Acc')\n",
    "        plt.plot(history['val_accuracy'], label='Val Acc')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy curves')\n",
    "        plt.savefig(os.path.join(output_dir, 'accuracy_curves.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Plot other validation metric trends (same as before)\n",
    "        epochs_range = range(1, len(history['val_loss']) + 1)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(epochs_range, history['val_precision'], label='Val Precision')\n",
    "        plt.plot(epochs_range, history['val_recall'], label='Val Recall')\n",
    "        plt.plot(epochs_range, history['val_f1'], label='Val F1')\n",
    "        plt.plot(epochs_range, history['val_iou'], label='Val IoU')\n",
    "        plt.plot(epochs_range, history['val_dice'], label='Val Dice')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Score'); plt.legend(); plt.title('Validation metrics over epochs')\n",
    "        plt.savefig(os.path.join(output_dir, 'val_metrics_trends.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # AUC trends\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(epochs_range, [x if x is not None else np.nan for x in history['val_pr_auc']], label='Val PR-AUC')\n",
    "        plt.plot(epochs_range, [x if x is not None else np.nan for x in history['val_roc_auc']], label='Val ROC-AUC')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.legend(); plt.title('AUC trends')\n",
    "        plt.savefig(os.path.join(output_dir, 'val_auc_trends.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Final ROC and PR curves using last validation arrays (if available)\n",
    "        try:\n",
    "            if 'all_val_probs' in locals() and all_val_probs.size > 0 and all_val_targets.size > 0:\n",
    "                if np.unique(all_val_targets).size > 1:\n",
    "                    fpr, tpr, _ = roc_curve(all_val_targets, all_val_probs)\n",
    "                    roc_auc_val = roc_auc_score(all_val_targets, all_val_probs)\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                    plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc_val:.4f}')\n",
    "                    plt.plot([0,1],[0,1], linestyle='--')\n",
    "                    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve (last val epoch)')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(os.path.join(output_dir, 'roc_curve_last_epoch.png'))\n",
    "                    plt.close()\n",
    "                precision_vals, recall_vals, _ = precision_recall_curve(all_val_targets, all_val_probs)\n",
    "                pr_auc_val = auc(recall_vals, precision_vals)\n",
    "                plt.figure(figsize=(6,6))\n",
    "                plt.plot(recall_vals, precision_vals, label=f'PR AUC={pr_auc_val:.4f}')\n",
    "                plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall (last val epoch)')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(output_dir, 'pr_curve_last_epoch.png'))\n",
    "                plt.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "        # emergency save\n",
    "        try:\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, 'emergency_save.pth'))\n",
    "            print(\"Saved emergency checkpoint.\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        raise\n",
    "\n",
    "# ---------------------------\n",
    "# main()\n",
    "# ---------------------------\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    data_dir = filedialog.askdirectory(title=\"Select Directory with TEM Images and Masks\")\n",
    "    if not data_dir:\n",
    "        print(\"No directory selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_dir = os.path.join(data_dir, f'nanopore_model_{timestamp}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nStarting nanopore detection model training...\")\n",
    "    print(f\"Model checkpoints and outputs will be saved to: {output_dir}\")\n",
    "\n",
    "    try:\n",
    "        model = train_nanopore_detector(data_dir, output_dir,\n",
    "                                       batch_size=1,\n",
    "                                       epochs=30,\n",
    "                                       learning_rate=5e-5,\n",
    "                                       patience=3,\n",
    "                                       weight_decay=1e-4,\n",
    "                                       prob_threshold=0.5,\n",
    "                                       resize_to=(1024,1024))\n",
    "        print(\"\\nTraining complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
